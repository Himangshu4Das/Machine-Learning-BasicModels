{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17acd593",
   "metadata": {},
   "source": [
    "### What is regression?\n",
    "Regression searches for relationships among variables.<br>\n",
    ">The dependent features are called the dependent variables, outputs, or responses.<br>\n",
    ">The independent features are called the independent variables, inputs, regressors, or predictors.\n",
    "\n",
    "In regression problems we find relationships between the dependent and independent variables which are ultimately used to predict an output using given inputs ( independent variables )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f918510f",
   "metadata": {},
   "source": [
    "Let us have a set of independent variables 𝐱 = (𝑥₁, …, 𝑥ᵣ)<br>\n",
    "  where 𝑟 is the number of predictors<br>\n",
    "  \n",
    "We find a linear relationship between 𝑦 and 𝐱 using the regression equation: 𝑦 = 𝛽₀ + 𝛽₁𝑥₁ + ⋯ + 𝛽ᵣ𝑥ᵣ + 𝜀.<br>\n",
    "  where 𝛽₀, 𝛽₁, …, 𝛽ᵣ are the regression coefficients, and 𝜀 is the random error.\n",
    "\n",
    "Linear regression calculates the estimators of the regression coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7027b6",
   "metadata": {},
   "source": [
    "### What are residuals?\n",
    "The differences 𝑦ᵢ - f(𝐱ᵢ) for all observations 𝑖 = 1, …, 𝑛, are called the residuals.\n",
    " >where f(x) is the estimated function. ie. f(x<sub>i</sub>) = 𝑏₀ + 𝑏₁𝑥₁ + ⋯ + 𝑏<sub>i</sub>𝑥<sub>i</sub>\n",
    " \n",
    "The goal of applying linear regression is to find the best fit line AKA best weights AKA value of estimated function that generated the least residual!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf7c844",
   "metadata": {},
   "source": [
    "### Coefficient of determination (R<sup>2</sup>)\n",
    "The coefficient of determination, denoted as 𝑅², tells you which amount of variation in 𝑦 can be explained by the dependence on 𝐱, using the particular regression model. A larger 𝑅² indicates a better fit and means that the model can better explain the variation of the output with different inputs.\n",
    "\n",
    "The value 𝑅² = 1 corresponds to SSR = 0. That’s the perfect fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56bac8e",
   "metadata": {},
   "source": [
    "### Assumptions in regression\n",
    ">There should be a linear and additive relationship between dependent (response) variable and independent (predictor) variable(s). A linear relationship suggests that a change in response Y due to one unit change in X¹ is constant, regardless of the value of X¹. An additive relationship suggests that the effect of X¹ on Y is independent of other variables.\n",
    "\n",
    ">There should be no correlation between the residual (error) terms. Absence of this phenomenon is known as Autocorrelation.\n",
    "\n",
    ">The independent variables should not be correlated. Absence of this phenomenon is known as multicollinearity.\n",
    "\n",
    ">The error terms must have constant variance. This phenomenon is known as homoskedasticity. The presence of non-constant variance is referred to heteroskedasticity.\n",
    "\n",
    ">The error terms must be normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067b9802",
   "metadata": {},
   "source": [
    "### Simple Linear Regression\n",
    "Simple or single-variate linear regression is the simplest case of linear regression, as it has a single independent variable, 𝐱 = 𝑥."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3b7c387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80365764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating sample data\n",
    "x = np.array([5, 15, 25, 35, 45, 55]).reshape((-1, 1)) #one column and as many rows as necessary (2D array -independent variable)\n",
    "y = np.array([5, 20, 14, 32, 22, 38])                  # 1D array (dependent variable)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b36a64e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model and fitting\n",
    "model = LinearRegression().fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481858e5",
   "metadata": {},
   "source": [
    "Parameters that can be set on the model\n",
    " 1. <b>fit_intercept</b> is a Boolean that, if True, decides to calculate the intercept 𝑏₀ or, if False, considers it equal to zero. It defaults to True.\n",
    " 2. <b>normalize</b> is a Boolean that, if True, decides to normalize the input variables. It defaults to False, in which case it doesn’t normalize the input variables.\n",
    " 3. <b>copy_X</b> is a Boolean that decides whether to copy (True) or overwrite the input variables (False). It’s True by default.\n",
    " 4. <b>n_jobs</b> is either an integer or None. It represents the number of jobs used in parallel computation. It defaults to None, which usually means one job. -1 means to use all available processors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3291231e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.715875613747954\n",
      "5.633333333333333\n",
      "[0.54]\n"
     ]
    }
   ],
   "source": [
    "# Show R-square\n",
    "r = model.score(x, y)\n",
    "print(r)\n",
    "\n",
    "# Show intercept of the estimated line (b0)\n",
    "print(model.intercept_)\n",
    "\n",
    "# Show b1\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af2be7f",
   "metadata": {},
   "source": [
    "The value of 𝑏₀ is approximately 5.63. This illustrates that your model predicts the response 5.63 when 𝑥 is zero. The value 𝑏₁ = 0.54 means that the predicted response rises by 0.54 when 𝑥 is increased by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27178a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.33333333 13.73333333 19.13333333 24.53333333 29.93333333 35.33333333]\n"
     ]
    }
   ],
   "source": [
    "# Predicting results (using train data as test data)\n",
    "y_pred = model.predict(x)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74490e9",
   "metadata": {},
   "source": [
    "model.predict simple plots the estimated line, which can also be calculated manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e9d06e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.33333333 13.73333333 19.13333333 24.53333333 29.93333333 35.33333333]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.intercept_ + model.coef_ * x\n",
    "print(y_pred.reshape(1,-1).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4ad3219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.63333333 6.17333333 6.71333333 7.25333333]\n"
     ]
    }
   ],
   "source": [
    "# Predicting results ( using new test data)\n",
    "x_new = np.arange(4).reshape((-1, 1))\n",
    "y_pred_new = model.predict(x_new)\n",
    "print(y_pred_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff7042e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
